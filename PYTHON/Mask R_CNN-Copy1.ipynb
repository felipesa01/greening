{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a205e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../PYTHON/HLB')\n",
    "import orange_canopy_tif as orca\n",
    "import gdalbasics as gdb\n",
    "\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage\n",
    "\n",
    "logs = '../Mask_RCNN/logs'\n",
    "dataset = '../Mask_RCNN/datasets/canopy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa402c",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60855da",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = orca.OrangeCanopyConfig()\n",
    "# config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84191dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = '../Mask_RCNN/mask_rcnn_coco.h5'\n",
    "# weights = '../Mask_RCNN/logs/trees.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55585dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights, \n",
    "                   by_name=True,\n",
    "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c120b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = orca.OrangeCanopyDataset()\n",
    "train_dataset.load_data(dataset, 'train')\n",
    "train_dataset.prepare()\n",
    "\n",
    "val_dataset = orca.OrangeCanopyDataset()\n",
    "val_dataset.load_data(dataset, 'val')\n",
    "val_dataset.prepare()\n",
    "\n",
    "augmentation = iaa.SomeOf((0, 2), [iaa.Fliplr(0.5), iaa.Flipud(0.5), iaa.OneOf([iaa.Affine(rotate=90), iaa.Affine(rotate=180), iaa.Affine(rotate=270)]), iaa.Multiply((0.5, 1.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15279714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_dataset, val_dataset,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=4,\n",
    "            augmentation=augmentation,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd55f0",
   "metadata": {},
   "source": [
    "# InferÃªncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7ea6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(orca.OrangeCanopyConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    # I kept the same configuration of the training\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    NAME = 'trees'\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    BACKBONE = \"resnet50\"\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    BACKBONE_STRIDES = [4, 8, 16, 32, 64]\n",
    "    RPN_ANCHOR_SCALES = (4, 8, 16, 32, 64)\n",
    "    USE_MINI_MASK = False\n",
    "    IMAGE_CHANNEL_COUNT = 3\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "    MEAN_PIXEL = np.array([105, 236, 189])\n",
    "    DETECTION_NMS_THRESHOLD = 0.3\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    MAX_GT_INSTANCES = 100\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    TRAIN_ROIS_PER_IMAGE = 100\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 100\n",
    "    \n",
    "config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b501d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/felipesa/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:From /home/felipesa/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode='inference', config=config, model_dir=logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc4ad07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 12\n"
     ]
    }
   ],
   "source": [
    "weights = '../Mask_RCNN/logs/oranges_trees_canopy20210803T1653/mask_rcnn_oranges_trees_canopy_0012.h5'\n",
    "\n",
    "model.load_weights(weights, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d1b7eac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (256, 256, 3)         min:    0.00000  max:  253.00000  uint16\n",
      "molded_images            shape: (1, 256, 256, 3)      min: -233.00000  max:  147.00000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  256.00000  int64\n",
      "anchors                  shape: (1, 16368, 4)         min:   -0.17747  max:    0.99541  float32\n"
     ]
    }
   ],
   "source": [
    "images_test_dir = os.path.join(dataset, 'real_test', 'images', 'TIF')\n",
    "# images_test_dir = '../IMGS'\n",
    "\n",
    "image_paths = []\n",
    "for filename in os.listdir(images_test_dir):\n",
    "    if os.path.splitext(filename)[1].lower() in ['.tif']:\n",
    "        image_paths.append(os.path.join(images_test_dir, filename))\n",
    "\n",
    "\n",
    "shape_path_aux = dataset + '/results/'\n",
    "temp_path_prediction = dataset + '/results/' + 'TEMP_RESP.tif'\n",
    "shape_prediction_name = 'pred_image'\n",
    "shape_prediction_ext = '.shp'\n",
    "\n",
    "for path in image_paths:\n",
    "    array, image_tif = gdb.readimagetif(path, 'Integer')\n",
    "    result = model.detect([array[:,:,0:3]], verbose=1)[0]\n",
    "    masks = result['masks']\n",
    "    dim_masks = masks.shape\n",
    "    masks_final = np.zeros((dim_masks[0], dim_masks[1]), dtype=np.int32)\n",
    "    for cont_mask in range(dim_masks[2]):\n",
    "        aux = masks[:, :, cont_mask].copy()\n",
    "        for j in range(aux.shape[0]):\n",
    "            for i in range(aux.shape[1]):\n",
    "                if aux[j, i] != 0:\n",
    "                    masks_final[j, i] = (cont_mask + 1)\n",
    "                # end if\n",
    "            # end for\n",
    "        # end for\n",
    "    # end for\n",
    "\n",
    "    # save the shape\n",
    "    origin_x, pixel_width, rot_x, origin_y, rot_y, pixel_height = image_tif.GetGeoTransform()\n",
    "    drive = image_tif.GetDriver()\n",
    "    projection = image_tif.GetProjection()\n",
    "    raster_origin = (origin_y, origin_x)\n",
    "    gdb.array2raster(temp_path_prediction, 'Integer', raster_origin, pixel_height, pixel_width, rot_y, rot_x, drive, projection, masks_final)\n",
    "    shape_path = shape_path_aux + shape_prediction_name + str(path[-8:-4]) + shape_prediction_ext\n",
    "    gdb.raster2polygon(temp_path_prediction, shape_path, 'real_test')\n",
    "    masks_final = None\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf34ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'],\n",
    "                                val_dataset.class_names, r['scores'], figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7a1bb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Mask_RCNN/datasets/canopy/result/pred_image0342.shp'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ff777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcnn",
   "language": "python",
   "name": "rcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
