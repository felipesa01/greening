{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e94b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "import hlb_utils as hlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8741a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlay(gpd_canopy_r, gpd_canopy_e):\n",
    "    \n",
    "    over = gpd.overlay(gpd_canopy_r, gpd_canopy_e)\n",
    "    #over = over.loc[over['id_1'] != over['id_2']].explode().reset_index(drop=True)\n",
    "    if over.shape[0] != 0:        \n",
    "        over['geo_id1'] = gpd_canopy_r.loc[list(over['id_1']), 'geometry'].values\n",
    "        over['geo_id2'] = gpd_canopy_e.loc[list(over['id_2']), 'geometry'].values\n",
    "    return over\n",
    "\n",
    "\n",
    "def get_pairs(canopy_r, canopy_e):\n",
    "    pairs = {}\n",
    "\n",
    "    with tqdm(total=len(canopy_r.index)) as pbar:\n",
    "        pbar.set_description(\"Identificando pares\")\n",
    "        sleep(0.1)\n",
    "\n",
    "        for i in canopy_r.index:\n",
    "\n",
    "            polygon = canopy_r.loc[i, 'geometry']\n",
    "\n",
    "            over = canopy_e.intersection(polygon)\n",
    "            over = over.loc[~over.is_empty]\n",
    "\n",
    "            if over.shape[0] > 1:\n",
    "                id_ext = over.area.sort_values(ascending=False).index[0]\n",
    "            elif over.shape[0] == 1:\n",
    "                id_ext = over.area.index[0]\n",
    "            else:\n",
    "                id_ext = -999\n",
    "\n",
    "            if id_ext != -999 and type(over.loc[id_ext]) != type(None):\n",
    "                if over.loc[id_ext].geom_type == 'Polygon':\n",
    "                    pairs[i] = id_ext\n",
    "            id_ext = -999\n",
    "            pbar.update(1)      \n",
    "        \n",
    "    return pairs\n",
    "\n",
    "\n",
    "def get_label_pairs(pairs):\n",
    "    label_pairs = []\n",
    "    for k, v in pairs.items():\n",
    "        label_pairs.append(str(float(k))+'-'+str(float(v)))\n",
    "        \n",
    "    return label_pairs\n",
    "\n",
    "    \n",
    "def compile_data(canopy_r, canopy_e, pairs):\n",
    "    \n",
    "    label_pairs = get_label_pairs(pairs)\n",
    "    \n",
    "    intersec = get_overlay(canopy_r, canopy_e)\n",
    "    intersec['label_id'] = [str(float(i1)) + '-' + str(float(i2)) for i1, i2 in zip(list(intersec['id_1']), list(intersec['id_2']))]\n",
    "    intersec = intersec.loc[intersec['label_id'].isin(label_pairs)]\n",
    "    intersec = intersec.drop_duplicates('id_2')\n",
    "    \n",
    "    intersec['geo_union'] = intersec['geo_id1'].union(intersec['geo_id2'])\n",
    "    intersec['IoU'] = intersec['geometry'].area/intersec['geo_union'].area\n",
    "    \n",
    "    return intersec\n",
    "\n",
    "    \n",
    "def get_TruePositive(gpd_intersection, IoU_threshold = 0.5):\n",
    "    TP = gpd_intersection.loc[gpd_intersection['IoU'] > IoU_threshold]    \n",
    "    return TP\n",
    "\n",
    "\n",
    "def get_TruePositive2(gpd_intersection, IoU_threshold = 0.5):\n",
    "    TP = gpd_intersection[over['geometry'].area > IoU_threshold * gpd_intersection['geo_id1'].area]\n",
    "    TP = TP.loc[TP['geometry'].contains(TP['geo_id1'].centroid)]\n",
    "    \n",
    "    TP.drop_duplicates('geo_id1', inplace=True)\n",
    "    TP.drop_duplicates('geo_id2', inplace=True)\n",
    "    \n",
    "    return TP\n",
    "\n",
    "\n",
    "def calculate_IoU(gpd_TruePositive):\n",
    "    list_union = []\n",
    "    for i in gpd_TruePositive.index:\n",
    "        union = gpd_TruePositive.loc[i, 'geo_id1'].union(gpd_TruePositive.loc[i, 'geo_id2'])\n",
    "        list_union.append(union)\n",
    "\n",
    "    gpd_TruePositive['union_geo'] = list_union\n",
    "    gpd_TruePositive['IoU'] = gpd_TruePositive['geometry'].area / gpd.GeoSeries(gpd_TruePositive['union_geo']).area\n",
    "    return gpd_TruePositive\n",
    "\n",
    "\n",
    "def get_FalseNegative(gpd_canopy_r, gpd_TruePositive):\n",
    "    return canopy_r.loc[[x for x in canopy_r.index if x not in list(gpd_TruePositive['id_1'])]]\n",
    "\n",
    "\n",
    "def get_FalsePositive(gpd_canopy_e, gpd_TruePositive):\n",
    "    return gpd_canopy_e.loc[[x for x in gpd_canopy_e.index if x not in list(gpd_TruePositive['id_2'])]]\n",
    "\n",
    "def get_metrics(canopy_r, canopy_e):\n",
    "\n",
    "    canopy_e['id'] = canopy_e.index\n",
    "    canopy_e['id'] = canopy_e.index\n",
    "\n",
    "    pares = get_pairs(canopy_r, canopy_e)\n",
    "    dados = compile_data(canopy_r, canopy_e, pares)\n",
    "\n",
    "    TP = get_TruePositive(dados)\n",
    "    FN = get_FalseNegative(canopy_r, TP)\n",
    "    FP = get_FalsePositive(canopy_e, TP)\n",
    "\n",
    "    precision = TP.shape[0]/(TP.shape[0]+FP.shape[0])\n",
    "    recall = TP.shape[0]/(TP.shape[0]+FN.shape[0])\n",
    "\n",
    "    if precision + recall != 0:\n",
    "        f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return (precision, recall, f1_score), (TP, FN, FP), dados\n",
    "\n",
    "def iter_detection_score(canopy_e):\n",
    "    slices = {}\n",
    "    \n",
    "    for i in np.arange(0.90, 1, 0.01):\n",
    "        df = canopy_e.loc[canopy_e['detection_score'] >= i].copy()\n",
    "        \n",
    "        slices[round(i, 2)] = df\n",
    "    \n",
    "    return slices\n",
    "\n",
    "def get_threshold_gaph(canopy_r, canopy_e):\n",
    "    \n",
    "    slices = iter_detection_score(canopy_e)\n",
    "    \n",
    "    \n",
    "    metrics_dic = {}\n",
    "    \n",
    "    for k, v in slices.items():\n",
    "        \n",
    "        metrics, _, _ = get_metrics(canopy_r, v)\n",
    "        \n",
    "        metrics_dic[k] = metrics\n",
    "        \n",
    "    return metrics_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a54b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mAP(over, gpd_canopy_r, gpd_canopy_e):\n",
    "    \n",
    "    precision_list = []\n",
    "    for i in np.arange(0.5, 0.96, 0.05):\n",
    "        \n",
    "        TP = get_TruePositive(over, i)\n",
    "        FP = get_FalsePositive(gpd_canopy_e, TP)\n",
    "        \n",
    "        precision = TP.shape[0]/(TP.shape[0]+FP.shape[0])\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        \n",
    "    return np.mean(precision_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b45505",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = 'dem'\n",
    "shape_path_aux = '../datasets/segmentacao_todos/results_{}/'.format(sector)\n",
    "\n",
    "result_paths = []\n",
    "for filename in os.listdir(shape_path_aux):\n",
    "    if os.path.splitext(filename)[1].lower() == '.geojson':\n",
    "        result_paths.append(os.path.join(shape_path_aux, filename))\n",
    "\n",
    "pols = pd.concat([gpd.read_file(i) for i in result_paths], axis=0).reset_index(drop=True)\n",
    "pols = pols[pols.geometry.is_valid]\n",
    "pols['geometry'] = pols.buffer(0.1).buffer(-0.1).simplify(0.03)\n",
    "pols = pols.explode('geometry').reset_index(drop=True)\n",
    "pols.set_index(keys=pd.Index(range(1, pols.shape[0] + 1)), inplace=True)\n",
    "pols['id'] = pols.index\n",
    "\n",
    "pols.to_file('../datasets/segmentacao_todos/merged_{}.geojson'.format(sector), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = 'dem'\n",
    "\n",
    "P = hlb.Processing()\n",
    "canopy_e, pols_filtred = P.join_vectors('../datasets/segmentacao_todos/results_{}'.format(sector))\n",
    "\n",
    "canopy_e.to_file('../datasets/segmentacao_todos/canopy_{}_raw.geojson'.format(sector), driver='GeoJSON')\n",
    "pols_filtred.to_file('../datasets/segmentacao_todos/canopy_{}_filtred.geojson'.format(sector), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ffb749",
   "metadata": {},
   "source": [
    "## Mask RCNN + Patch_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509a1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "canopy_r = gpd.read_file('D:/FelipeSa/OneDrive/Felipe_INPE/Segmentacao/Analise_final/train_canopy_all_cut_final.geojson')\n",
    "canopy_r['id'] = canopy_r.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd24b7f",
   "metadata": {},
   "source": [
    "### RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8bafc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "canopy_e = gpd.read_file('..\\datasets\\segmentacao_todos\\canopies_rgb_filtered.geojson')\n",
    "canopy_e['id'] = canopy_e.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3a8f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Identificando pares: 100%|█████████████████████████████████████████████████████████| 2026/2026 [02:03<00:00, 16.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# df = canopy_e.loc[canopy_e['detection_score'] >= 0.99].copy()\n",
    "df = canopy_e.copy()\n",
    "\n",
    "metrics, dfs, _ = get_metrics(canopy_r, df)\n",
    "\n",
    "(TP, FN, FP) = dfs\n",
    "\n",
    "#FN.to_file('..\\datasets\\segmentacao_todos\\FN_rgb.geojson', driver='GeoJSON')\n",
    "#FP.to_file('..\\datasets\\segmentacao_todos\\FP_rgb.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FN.to_file('..\\datasets\\segmentacao_todos\\FN_rgb2.geojson', driver='GeoJSON')\n",
    "FP.to_file('..\\datasets\\segmentacao_todos\\FP_rgb2.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0fcb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9861042183622829, 0.9807502467917077, 0.9834199455580303)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fc1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513fe0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rgb = get_threshold_gaph(canopy_r, canopy_e)\n",
    "data_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_rgb.keys(), data_rgb.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8437145",
   "metadata": {},
   "source": [
    "### DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1413fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "canopy_e = gpd.read_file('..\\datasets\\segmentacao_todos\\canopies_dem_filtered.geojson')\n",
    "canopy_e['id'] = canopy_e.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e4c577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Identificando pares: 100%|█████████████████████████████████████████████████████████| 2026/2026 [02:02<00:00, 16.55it/s]\n"
     ]
    }
   ],
   "source": [
    "#df = canopy_e.loc[canopy_e['detection_score'] >= 0.99].copy()\n",
    "df = canopy_e.copy()\n",
    "\n",
    "metrics, dfs, _ = get_metrics(canopy_r, df)\n",
    "\n",
    "(TP, FN, FP) = dfs\n",
    "\n",
    "FN.to_file('..\\datasets\\segmentacao_todos\\FN_dem.geojson', driver='GeoJSON')\n",
    "FP.to_file('..\\datasets\\segmentacao_todos\\FP_dem.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64dc39aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9889280322093609, 0.9698914116485686, 0.9793172190381261)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dem = get_threshold_gaph(canopy_r, canopy_e)\n",
    "data_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5147771",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_dem.keys(), data_dem.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39822227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76baf0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a327a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1058a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e02ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TruePositive(gpd_intersection, IoU_threshold = 0.5):\n",
    "    TP = intersec.loc[intersec['IoU']>IoU_threshold]\n",
    "    \n",
    "    return TP\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be117f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mAP(intersec, canopy_r, canopy_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ce8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eabcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Artigo: Extraction of information about individual trees from high-spatial-resolution uav-acquired images of an orchard\n",
    "## Métrica: Classes de resultado\n",
    "\n",
    "over = get_intersection(canopy_r, canopy_e)\n",
    "match = calculate_matches(over)\n",
    "\n",
    "canopy_e['result'] = ''\n",
    "canopy_e.at[match['id_2'].values, 'result'] = 'match'\n",
    "\n",
    "# canopy_e.to_file('../datasets/segmentacao_todos/validacao_over-match.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Artigo: Mask R-CNN refitting strategy for plant counting and sizing in uav imagery\n",
    "## Metrica: mean Average Precision (mAP)\n",
    "\n",
    "over = get_intersection(canopy_r, canopy_e)\n",
    "TP = get_TruePositive(over)\n",
    "TP = calculate_IoU(TP)\n",
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbcd25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "canopy_e = gpd.read_file('..\\datasets\\segmentacao_todos\\canopy_detection_result_rgb_raw.geojson')\n",
    "canopy_e['id'] = canopy_e.index\n",
    "\n",
    "over = get_intersection(canopy_r, canopy_e)\n",
    "TP = get_TruePositive(over)\n",
    "TP = calculate_IoU(TP)\n",
    "FN = get_FalseNegative(canopy_r, TP)\n",
    "FP = get_FalsePositive(canopy_e, TP)\n",
    "\n",
    "precision = TP.shape[0]/(TP.shape[0]+FP.shape[0])\n",
    "recall = TP.shape[0]/(TP.shape[0]+FN.shape[0])\n",
    "\n",
    "if precision + recall != 0:\n",
    "    f1_score = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "precision, recall, f1_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcnn",
   "language": "python",
   "name": "rcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
