{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import line_orchard_detection as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..\\datasets\\inferencia_sobradinho_areasul/'\n",
    "\n",
    "## section = 'pera2'\n",
    "\n",
    "pontos = gpd.read_file(path + 'centroids.geojson')\n",
    "\n",
    "linhas, pts = ld.detect_lines_uni(pontos, row_inverse=False, pt_inverse=False)\n",
    "\n",
    "linhas.to_file(path + 'line_prediction.geojson', driver='GeoJSON')\n",
    "pts.to_file(path + 'centroids_mapped.geojson', driver='GeoJSON')\n",
    "# falhas.to_file(path + 'falhas_prediction.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pols = gpd.read_file(path + 'canopy_detection_result.geojson')\n",
    "pols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pols.loc[[0,1],'area'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pols['area'] = pols['geometry'].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pols_sort = pols.sort_values('area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pols_sort['id']:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linhas = linhas.loc[linhas['id']>0]\n",
    "linhas.to_file(path + 'line_prediction.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(pontos.row.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos = gpd.read_file(path + 'centroides_area_mapped.geojson')\n",
    "\n",
    "\n",
    "ids_rows = []\n",
    "geom_rows = []\n",
    "for i in list(set(pontos.row.values)):\n",
    "    df = pontos.loc[pontos['row']==1,:]\n",
    "    \n",
    "    ids_rows.append(i)\n",
    "    geom_rows.append(LineString(df.sort_values('id_row').geometry.values))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame({'id': ids_rows, 'geometry':geom_rows}, crs=pontos.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "\n",
    "LineString(df.sort_values('id_row').geometry.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontos.loc[pontos['buffer']==2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..\\datasets\\inferencia_sobradinho_areasul/'\n",
    "\n",
    "pontos = gpd.read_file(path + 'centroids.geojson')\n",
    "\n",
    "linhas, points = ld.row_segments(pontos)\n",
    "geodf = gpd.GeoDataFrame({'geometry':gpd.GeoSeries(linhas, crs=pontos.crs)})\n",
    "# geodf = extrapolar_linhas(geodf)\n",
    "buffer = ld.get_buffer(geodf)\n",
    "lines = ld.buffer_to_rows(buffer, points)\n",
    "points = ld.mapping_rows(points, lines)\n",
    "\n",
    "geodf.to_file(path + 'lines_prediction1.geojson', driver='GeoJSON')\n",
    "\n",
    "linhas_novas = ld.snap_rows(points, lines)\n",
    "\n",
    "for i in linhas_novas:\n",
    "    linhas.append(i)\n",
    "\n",
    "geodf = gpd.GeoDataFrame({'geometry':gpd.GeoSeries(linhas, crs=points.crs)})\n",
    "# geodf = extrapolar_linhas(geodf)\n",
    "buffer = ld.get_buffer(geodf)\n",
    "lines = ld.buffer_to_rows(buffer, points)\n",
    "points = ld.mapping_rows(points, lines)\n",
    "\n",
    "geodf.to_file(path + 'lines_prediction2.geojson', driver='GeoJSON')\n",
    "\n",
    "linhas_novas = ld.snap_rows(points, lines)\n",
    "\n",
    "for i in linhas_novas:\n",
    "    linhas.append(i)\n",
    "\n",
    "geodf = gpd.GeoDataFrame({'geometry':gpd.GeoSeries(linhas, crs=points.crs)})\n",
    "# geodf = extrapolar_linhas(geodf)\n",
    "buffer = ld.get_buffer(geodf)\n",
    "lines = ld.buffer_to_rows(buffer, points)\n",
    "points = ld.mapping_rows(points, lines)\n",
    "\n",
    "geodf.to_file(path + 'lines_prediction3.geojson', driver='GeoJSON')\n",
    "\n",
    "for i in linhas_novas:\n",
    "    linhas.append(i)\n",
    "\n",
    "geodf = gpd.GeoDataFrame({'geometry':gpd.GeoSeries(linhas, crs=points.crs)})\n",
    "# geodf = extrapolar_linhas(geodf)\n",
    "buffer = ld.get_buffer(geodf)\n",
    "lines = ld.buffer_to_rows(buffer, points)\n",
    "points = ld.mapping_rows(points, lines)\n",
    "\n",
    "geodf.to_file(path + 'lines_prediction4.geojson', driver='GeoJSON')\n",
    "\n",
    "# falhas.to_file(path + 'falhas_prediction.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../VECTOR/Area/'\n",
    "\n",
    "pontos = gpd.read_file(path + 'centroides_area_aut_pera.geojson')\n",
    "\n",
    "unit_segments, points = row_segments(pontos)\n",
    "df_segments = gpd.GeoDataFrame({'geometry': gpd.GeoSeries(unit_segments, crs=pontos.crs)})\n",
    "print('OK1')\n",
    "buffer = get_buffer(df_segments)\n",
    "rows = buffer_to_rows(buffer, points)\n",
    "print('OK2')\n",
    "points = mapping_rows(points, rows)\n",
    "\n",
    "points_new = gpd.GeoDataFrame()\n",
    "\n",
    "stop = True\n",
    "while stop:\n",
    "\n",
    "    if not points_new.empty:\n",
    "        points = points_new.copy()\n",
    "\n",
    "    new_segments = snap_rows(points, rows)\n",
    "\n",
    "    if len(new_segments) > 0:\n",
    "        for i in new_segments:\n",
    "            unit_segments.append(i)\n",
    "\n",
    "        df_segments = gpd.GeoDataFrame({'geometry': gpd.GeoSeries(unit_segments, crs=points.crs)})\n",
    "        buffer = get_buffer(df_segments)\n",
    "        rows = buffer_to_rows(buffer, points)\n",
    "        points_new = mapping_rows(points, rows)\n",
    "    else:\n",
    "        stop = False\n",
    "\n",
    "# Detectar falhas\n",
    "points_new['gap'] = 0\n",
    "points_new = detect_gaps(points_new, rows)\n",
    "rows = buffer_to_rows(buffer, points_new, pt_inverse=True)\n",
    "\n",
    "## Editar saidas ##\n",
    "# linhas\n",
    "rows.rename(columns={'id_sort': 'id'}, inplace=True)\n",
    "id_final = list(rows['id'])\n",
    "if row_inverse:\n",
    "    # rows = rows.assign(id=rows.id.values[::-1])\n",
    "    id_final.reverse()\n",
    "#\n",
    "rows['id'] = id_final\n",
    "\n",
    "# Centroides\n",
    "points_new.drop(['pt_{}'.format(i) for i in range(1, 16)], axis=1, inplace=True)\n",
    "points_new.drop('line', axis=1, inplace=True)\n",
    "points_new.rename(columns={'buffer': 'row'}, inplace=True)\n",
    "points_new.row = points_new.row + 1  # index 1-based\n",
    "\n",
    "if row_inverse:\n",
    "    id_row = list(set(list(points_new.row.values)))\n",
    "    id_row_inv = id_row[::-1]\n",
    "    points_new.insert(4, 'row_ord', -99)\n",
    "    for old, new in zip(id_row, id_row_inv):\n",
    "        points_new.at[points_new['row'] == old, 'row_ord'] = new\n",
    "\n",
    "    points_new.drop('row', axis=1, inplace=True)\n",
    "    points_new.rename(columns={'row_ord': 'row'}, inplace=True)\n",
    "\n",
    "label_id = ['{row:03}-{pt:04}'.format(row=r, pt=p) for r, p in\n",
    "            zip(list(points_new['row']), list(points_new['id_row']))]\n",
    "points_new.insert(1, 'label_id', label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = points.copy()\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste.at[points_within[points_within].index, 'id_row'] = id_points_in_row\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_within[points_within].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "def get_angle(p1, p2):\n",
    "    y = p2.y - p1.y\n",
    "    x = p2.x - p1.x\n",
    "\n",
    "    angle = np.degrees(np.arctan2(y, x))\n",
    "\n",
    "    return angle\n",
    "\n",
    "\n",
    "def get_angle_vertex(p1, p_middle, p2):\n",
    "    get_angle(p_middle, p1)\n",
    "    get_angle(p_middle, p2)\n",
    "\n",
    "    angle = get_angle(p_middle, p1) - get_angle(p_middle, p2)\n",
    "\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "\n",
    "    return angle\n",
    "\n",
    "\n",
    "def is_line(p1, p_middle, p2, angle_threshold=15):\n",
    "    angle = get_angle_vertex(p1, p_middle, p2)\n",
    "\n",
    "    if abs(angle - 180) <= angle_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_extrapoled_line(p1, p2):\n",
    "    \"\"\"Creates a line extrapoled in p1->p2 direction\"\"\"\n",
    "    extrapol_ratio = 1\n",
    "    # a = p1\n",
    "    b = (p1[0] + extrapol_ratio * (p2[0] - p1[0]), p1[1] + extrapol_ratio * (p2[1] - p1[1]))\n",
    "    return b\n",
    "\n",
    "\n",
    "def round_school(x):\n",
    "    i, f = divmod(x, 1)\n",
    "    return int(i + ((f >= 0.5) if (x > 0) else (f > 0.5)))\n",
    "\n",
    "\n",
    "def get_centroids(canopy):\n",
    "    return gpd.GeoDataFrame({'geometry': canopy.centroid}, crs=canopy.crs)\n",
    "\n",
    "\n",
    "def row_segments(points):\n",
    "    points.reset_index(drop=True, inplace=True)\n",
    "    points.set_index(points.index + 1, inplace=True)\n",
    "    points['id'] = points.index\n",
    "\n",
    "    n_array = np.array(list(points.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    btree = cKDTree(n_array)\n",
    "    n_nearest = 16\n",
    "    dist, idx = btree.query(n_array, k=n_nearest)\n",
    "\n",
    "    for i in range(1, n_nearest):\n",
    "        points['pt_{}'.format(i)] = idx[:, i] + 1\n",
    "\n",
    "    segments = []\n",
    "    for i in points.index:\n",
    "\n",
    "        first = points.loc[points.loc[i, 'pt_1'], 'geometry']\n",
    "        second = points.loc[points.loc[i, 'pt_2'], 'geometry']\n",
    "\n",
    "        if is_line(first, points.loc[i, 'geometry'], second):\n",
    "            segments.append(LineString([first, points.loc[i, 'geometry'], second]))\n",
    "    #             points.at[i, 'middle'] = True\n",
    "\n",
    "    return segments, points\n",
    "\n",
    "\n",
    "# Nao mais utilizada\n",
    "def extrapolar_linhas(gdf):\n",
    "    for i in gdf.index:\n",
    "        coords = [[x, y] for x, y in zip(gdf.loc[i, 'geometry'].xy[0], gdf.loc[i, 'geometry'].xy[1])]\n",
    "        coords.append(['first'])\n",
    "        coords.append(['last'])\n",
    "        coords[0], coords[1], coords[2], coords[3] = coords[-2], coords[0], coords[1], coords[2]\n",
    "\n",
    "        coords[0] = get_extrapoled_line(coords[2], coords[1])\n",
    "        coords[-1] = get_extrapoled_line(coords[2], coords[3])\n",
    "\n",
    "        gdf.at[i, 'geometry'] = LineString(coords)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def get_buffer(geodf):\n",
    "    buffer = geodf['geometry'].buffer(0.5).unary_union  # .explode().reset_index(drop=True)\n",
    "    df_buffer = gpd.GeoDataFrame({\"geometry\": buffer}, crs=geodf.crs)\n",
    "    df_buffer.reset_index(drop=True)\n",
    "    # df_buffer.index = df_buffer.index + 1\n",
    "    return df_buffer\n",
    "\n",
    "\n",
    "def sort_rows(rows):\n",
    "    rows['id_sort'] = -99\n",
    "\n",
    "    x = np.array([x.coords.xy[0][int(len(x.coords.xy[0]) / 2)] for x in rows.geometry.values])\n",
    "    y = np.array([x.coords.xy[1][int(len(x.coords.xy[1]) / 2)] for x in rows.geometry.values])\n",
    "\n",
    "    rows['1st_coord'] = [str([round(x, 5), round(y, 5)]) for x, y in zip(x, y)]\n",
    "\n",
    "    points_selected = np.array([[x.coords.xy[0][int(len(x.coords.xy[0]) / 2)],\n",
    "                                 x.coords.xy[1][int(len(x.coords.xy[1]) / 2)]] for x in rows.geometry.values])\n",
    "\n",
    "    x_sorted = x.copy()\n",
    "    x_sorted.sort()\n",
    "\n",
    "    y_sorted = y.copy()\n",
    "    y_sorted.sort()\n",
    "\n",
    "    # Computar amplitudes\n",
    "    delta_x = x_sorted[-1] - x_sorted[0]\n",
    "    delta_y = y_sorted[-1] - y_sorted[0]\n",
    "\n",
    "    xy = []\n",
    "    if delta_x >= delta_y:\n",
    "        for z in x_sorted:\n",
    "            # gdf_linhas.at[gdf_linhas.geometry.values[0].coords.xy[0] == z]\n",
    "            xy.append(list(points_selected[points_selected[:, 0] == z][0]))\n",
    "    else:\n",
    "        for z in y_sorted:\n",
    "            # gdf_linhas.at[gdf_linhas.geometry.values[0].coords.xy[1] == z]\n",
    "            xy.append(list(points_selected[points_selected[:, 1] == z][0]))\n",
    "\n",
    "    xy = [str([round(i[0], 5), round(i[1], 5)]) for i in xy]\n",
    "\n",
    "    for i, coord in enumerate(xy):\n",
    "        rows.at[rows['1st_coord'] == coord, 'id_sort'] = i + 1\n",
    "\n",
    "    rows.drop('1st_coord', axis=1, inplace=True)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def buffer_to_rows(buffer, points, pt_inverse=False):\n",
    "    rows = []\n",
    "    points['buffer'] = -99\n",
    "    points['id_row'] = -99\n",
    "\n",
    "    # id_row = list(range(buffer.shape[0]))\n",
    "    # id_row_inverse = id_row[::-1]\n",
    "    # both = [[a, b] for a, b in zip(id_row, id_row_inverse)]\n",
    "    # id_row_mapping = {}\n",
    "    # for i in both:\n",
    "    #     if pt_inverse:\n",
    "    #         id_row_mapping[i[0]] = i[1]\n",
    "    #     else:\n",
    "    #         id_row_mapping[i[0]] = i[0]\n",
    "\n",
    "    for i in buffer.index:\n",
    "\n",
    "        # Busca os pontos dentro do polygono buffer\n",
    "        points_within = points.geometry.within(buffer.loc[i, 'geometry'])\n",
    "        df_points = points.loc[points_within[points_within].index, :]\n",
    "\n",
    "        x = np.array(df_points['geometry'].x)\n",
    "        y = np.array(df_points['geometry'].y)\n",
    "\n",
    "        xy_points = np.array([[x, y] for x, y in zip(df_points['geometry'].x, df_points['geometry'].y)])\n",
    "\n",
    "        x_sorted = x.copy()\n",
    "        x_sorted.sort()\n",
    "        y_sorted = y.copy()\n",
    "        y_sorted.sort()\n",
    "\n",
    "        # Computar amplitudes\n",
    "        delta_x = x_sorted[-1] - x_sorted[0]\n",
    "        delta_y = y_sorted[-1] - y_sorted[0]\n",
    "\n",
    "        xy = []\n",
    "        if delta_x >= delta_y:\n",
    "            for z in x_sorted:\n",
    "                xy.append(list(xy_points[xy_points[:, 0] == z][0]))\n",
    "        else:\n",
    "            for z in y_sorted:\n",
    "                xy.append(list(xy_points[xy_points[:, 1] == z][0]))\n",
    "\n",
    "        id_points_in_row = [i + 1 for i in range(points_within[points_within].shape[0])]\n",
    "        if pt_inverse:\n",
    "            id_points_in_row.reverse()\n",
    "\n",
    "        points.at[points_within[points_within].index, 'id_row'] = id_points_in_row\n",
    "        points.at[points_within[points_within].index, 'buffer'] = int(i)\n",
    "\n",
    "        rows.append(LineString(xy))\n",
    "\n",
    "    df_rows = gpd.GeoDataFrame({\"geometry\": gpd.GeoSeries(rows, crs=points.crs)})\n",
    "    # df_rows.reset_index(drop=True, inplace=True)\n",
    "    df_rows = sort_rows(df_rows)\n",
    "\n",
    "    return df_rows\n",
    "\n",
    "\n",
    "def mapping_rows(points, rows):\n",
    "    #     points['line'] = -99\n",
    "    points['line'] = ''\n",
    "\n",
    "    for i in rows.index:\n",
    "\n",
    "        # points_selected = points.loc[points['buffer'] == i]\n",
    "        line = rows.loc[i, 'geometry']\n",
    "\n",
    "        xy_line = [[x, y] for x, y in zip(line.xy[0], line.xy[1])]\n",
    "\n",
    "        first_point = Point(xy_line[0])\n",
    "        nea_first_point = Point(xy_line[1])\n",
    "\n",
    "        last_point = Point(xy_line[-1])\n",
    "        nea_last_point = Point(xy_line[-2])\n",
    "\n",
    "        id_first = points.loc[points['geometry'] == first_point].index[0]\n",
    "        id_nea_first = points.loc[points['geometry'] == nea_first_point].index[0]\n",
    "\n",
    "        id_last = points.loc[points['geometry'] == last_point].index[0]\n",
    "        id_nea_last = points.loc[points['geometry'] == nea_last_point].index[0]\n",
    "\n",
    "        points.at[id_first, 'line'] = 'first'\n",
    "        points.at[id_last, 'line'] = 'last'\n",
    "\n",
    "        if id_nea_first == id_nea_last:\n",
    "            points.at[id_nea_first, 'line'] = 'nearest'\n",
    "        else:\n",
    "            points.at[id_nea_first, 'line'] = 'first_nearest'\n",
    "            points.at[id_nea_last, 'line'] = 'last_nearest'\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def check_angle_from_distance(p0, p1, p2):\n",
    "    segment_origin = LineString([p0, p1])\n",
    "    segment_target = LineString([p1, p2])\n",
    "\n",
    "    ratio = segment_target.length / segment_origin.length\n",
    "\n",
    "    # Encontrei a eq. da reta aproximada formada pelas condições abaixo\n",
    "    # if ratio <= 0.7:\n",
    "    #     angle = 90\n",
    "    # elif ratio <= 1:\n",
    "    #     angle = 45\n",
    "    # elif ratio <= 2:\n",
    "    #     angle = 30\n",
    "    # elif ratio <= 3:\n",
    "    #     angle = 20\n",
    "    # elif ratio <= 4:\n",
    "    #     angle = 15\n",
    "    # else:\n",
    "    #     angle = 10\n",
    "\n",
    "    if ratio < 0.7:\n",
    "        angle = 90\n",
    "    elif ratio > 4:\n",
    "        angle = 15\n",
    "    else:\n",
    "        angle = 52.88450752 * ratio ** -0.8643306\n",
    "\n",
    "    return angle\n",
    "\n",
    "\n",
    "def select_bridge(potential_bridges):\n",
    "    \"\"\"\n",
    "    Encontra a ponte mais adequada, segundo as condições definidas, que liga o extremo da linha avaliada ao proximo\n",
    "    ponto. O ponto a ser ligado pela ponte escolhida deve ser um extremo de outra linha ou um ponto isolado até\n",
    "    então.\n",
    "\n",
    "    :param potential_bridges: lista de listas dos tres pontos formadores das pontes ([Point0, Point1, Point2] [,...])\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for ids, i in enumerate(potential_bridges):\n",
    "        # Para cada linha, são computadas as duas métricas abaixo:\n",
    "        # Ratio: Razao entre o segundo e o primeiro segmento formador da ponte\n",
    "        ratio = LineString([i[1], i[2]]).length / LineString([i[0], i[1]]).length\n",
    "        # Angle: Angulo formado entre os tres pontos formadores da ponte\n",
    "        angle = get_angle_vertex(i[0], i[1], i[2])\n",
    "\n",
    "        metrics[ids] = {'ratio': ratio, 'angle': angle}\n",
    "\n",
    "    # Dataframe com as metricas computadas. O indice do df segue a indexação da lista de entrada da funcao\n",
    "    df_select = pd.DataFrame(metrics).T\n",
    "    df_select.set_index(pd.Index([x for x in range(df_select.shape[0])]), inplace=True)\n",
    "\n",
    "    ## Filtragem inicial ##\n",
    "    # Exclusão das pontes em que o ratio é maior que 5\n",
    "    '''Isso significa que só serao consideradas as pontes que ligam o extremo das linhas \n",
    "    com os pontos que estao até 5x a distancia entre os seus dois ultimos pontos do extremo analisado'''\n",
    "    id_drop = df_select.loc[df_select['ratio'] > 5].index\n",
    "    df_select = df_select.drop(index=id_drop, axis=0)\n",
    "    # Fim da filtragem inicial ##\n",
    "\n",
    "    # Ordenação do dataframe pela metrica ratio\n",
    "    df_select = df_select.sort_values('ratio')\n",
    "\n",
    "    # Caso não haja remanescentes da filtragem, retona-se None\n",
    "    if df_select.empty:\n",
    "        return None\n",
    "    # Caso reste apenas uma ponte, ela é a selecionada\n",
    "    elif df_select.shape[0] == 1:\n",
    "        index = df_select.iloc[[0]].index[0]  # Aquisição inadequada do valor da célula (MELHORAR!!)\n",
    "    ## Selecão da ponte entre as remanescentes ##\n",
    "    else:\n",
    "        # Regras de selecao #\n",
    "        '''O fator prioritário na seleção da ponte é a distância do segundo segmento. Quando mais próximo do primeiro,\n",
    "        ou quanto menor a fracão, mais adequado. Entretanto, nos casos em que duas pontes apresentem tamanhos do\n",
    "        segundo segmento muito proximos (30%), o fator de escolha se torna o angulo formado pela ponte. Aquela de menor\n",
    "        angulaçao entre os seus tres pontos e a escolhida'''\n",
    "\n",
    "        menor_1 = df_select.iloc[0]['ratio']\n",
    "        menor_2 = df_select.iloc[1]['ratio']\n",
    "\n",
    "        if (menor_2 / menor_1) <= 1.3:\n",
    "            index = df_select.head(2).sort_values('angle').iloc[[0]].index[0]\n",
    "        else:\n",
    "            index = df_select.head(1).index[0]\n",
    "    ## Fim da selecao da ponte ##\n",
    "\n",
    "    bridge = potential_bridges[index]\n",
    "\n",
    "    return bridge\n",
    "\n",
    "\n",
    "def snap_rows(points, rows):\n",
    "    bridges = []\n",
    "    for i in rows.index:\n",
    "\n",
    "        selected = points.loc[points['buffer'] == i]\n",
    "\n",
    "        # Busca em cada extremo\n",
    "        for z in ['first', 'last']:\n",
    "\n",
    "            point_1 = selected.loc[selected['line'] == z]\n",
    "\n",
    "            if selected.shape[0] > 3:\n",
    "                point_0_label = z + '_nearest'\n",
    "            else:\n",
    "                point_0_label = 'nearest'\n",
    "\n",
    "            point_0 = selected.loc[selected['line'] == point_0_label]\n",
    "\n",
    "            potential_bridges = []\n",
    "            for y in range(1, 16):\n",
    "\n",
    "                num_point = point_1.loc[point_1.index[0], 'pt_{}'.format(y)]\n",
    "                point_2 = points.loc[points['id'] == num_point]\n",
    "\n",
    "                angle = check_angle_from_distance(point_0.iloc[0].geometry,\n",
    "                                                  point_1.iloc[0].geometry,\n",
    "                                                  point_2.iloc[0].geometry)\n",
    "\n",
    "                if is_line(point_0.iloc[0].geometry, point_1.iloc[0].geometry, point_2.iloc[0].geometry, angle):\n",
    "\n",
    "                    # Ponto encontrado corresponde a um extremo\n",
    "                    if point_2['line'].iloc[0] in ['first', 'last']:\n",
    "\n",
    "                        stop = False\n",
    "                        pt_sufix = 1\n",
    "                        point_aux = 0  # Só pela integridade do codigo\n",
    "                        while not stop:\n",
    "                            point_aux = points.loc[points['id'] == point_2['pt_{}'.format(pt_sufix)].iloc[0]]\n",
    "\n",
    "                            if 'nearest' in point_aux['line'].iloc[0]:\n",
    "                                stop = True\n",
    "                            pt_sufix += 1\n",
    "\n",
    "                        point_aux_geom = point_aux['geometry'].iloc[0]\n",
    "\n",
    "                        if is_line(point_1.iloc[0].geometry, point_2.iloc[0].geometry, point_aux_geom, 30):\n",
    "                            potential_bridges.append([point_0.iloc[0].geometry,\n",
    "                                                      point_1.iloc[0].geometry,\n",
    "                                                      point_2.iloc[0].geometry])\n",
    "\n",
    "                    # Ponto encontrado esta solto\n",
    "                    elif point_2['buffer'].iloc[0] == -99:\n",
    "                        potential_bridges.append([point_0.iloc[0].geometry,\n",
    "                                                  point_1.iloc[0].geometry,\n",
    "                                                  point_2.iloc[0].geometry])\n",
    "\n",
    "            if len(potential_bridges) <= 0:\n",
    "                pass\n",
    "            else:\n",
    "                selected_bridge = select_bridge(potential_bridges)\n",
    "\n",
    "                if selected_bridge is not None:\n",
    "                    bridges.append(LineString(selected_bridge))\n",
    "    return bridges\n",
    "\n",
    "\n",
    "def detect_gaps(points, rows):\n",
    "    gaps = gpd.GeoDataFrame({'id': -99,\n",
    "                             'buffer': -99,\n",
    "                             'gap': -99,\n",
    "                             'geometry': gpd.GeoSeries(crs=points.crs)})\n",
    "    id_pt = list(points['id'])[-1] + 1\n",
    "    for ids, i in zip(list(rows.index), rows['geometry']):\n",
    "\n",
    "        seg = list(map(LineString, zip(i.coords[:-1], i.coords[1:])))\n",
    "        segments = gpd.GeoSeries(seg, crs=rows.crs)\n",
    "\n",
    "        dist = (segments.length.quantile(0.5) + segments.length.quantile(0.6)) / 2\n",
    "\n",
    "        maiores = segments[segments.length > 1.05 * dist]\n",
    "\n",
    "        if maiores.shape[0] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            target_lines = round((maiores.length / dist), 2)\n",
    "            index = target_lines.index\n",
    "            split = list(target_lines)\n",
    "\n",
    "            for idx, z in zip(index, split):\n",
    "                z = round_school(z)\n",
    "                slices = pd.Series([x / z for x in range(1, z)])\n",
    "                for y in slices:\n",
    "                    gap = maiores.loc[[idx]].interpolate(y, normalized=True)\n",
    "                    df_gap = gpd.GeoDataFrame({'id': id_pt,\n",
    "                                               'buffer': ids,\n",
    "                                               'gap': 1,\n",
    "                                               'geometry': gap})\n",
    "                    gaps = pd.concat([gaps, df_gap], axis=0)\n",
    "\n",
    "                    id_pt += 1\n",
    "\n",
    "    points_new = pd.concat([points, gaps], axis=0)\n",
    "\n",
    "    return points_new\n",
    "\n",
    "\n",
    "def detect_lines_uni(df_points, row_inverse=False, pt_inverse=False):\n",
    "    # df_points = get_centroids(canopy)\n",
    "\n",
    "    unit_segments, points = row_segments(df_points)\n",
    "    df_segments = gpd.GeoDataFrame({'geometry': gpd.GeoSeries(unit_segments, crs=df_points.crs)})\n",
    "    buffer = get_buffer(df_segments)\n",
    "    rows = buffer_to_rows(buffer, points)\n",
    "    points = mapping_rows(points, rows)\n",
    "\n",
    "    points_new = gpd.GeoDataFrame()\n",
    "\n",
    "    stop = True\n",
    "    while stop:\n",
    "\n",
    "        if not points_new.empty:\n",
    "            points = points_new.copy()\n",
    "\n",
    "        new_segments = snap_rows(points, rows)\n",
    "\n",
    "        if len(new_segments) > 0:\n",
    "            for i in new_segments:\n",
    "                unit_segments.append(i)\n",
    "\n",
    "            df_segments = gpd.GeoDataFrame({'geometry': gpd.GeoSeries(unit_segments, crs=points.crs)})\n",
    "            buffer = get_buffer(df_segments)\n",
    "            rows = buffer_to_rows(buffer, points)\n",
    "            points_new = mapping_rows(points, rows)\n",
    "        else:\n",
    "            stop = False\n",
    "\n",
    "    # Detectar falhas\n",
    "    points_new['gap'] = 0\n",
    "    points_new = detect_gaps(points_new, rows)\n",
    "    rows = buffer_to_rows(buffer, points_new, pt_inverse=pt_inverse)\n",
    "\n",
    "    ## Editar saidas ##\n",
    "    # linhas\n",
    "    rows.rename(columns={'id_sort': 'id'}, inplace=True)\n",
    "    id_final = list(rows['id'])\n",
    "    if row_inverse:\n",
    "        # rows = rows.assign(id=rows.id.values[::-1])\n",
    "        id_final.reverse()\n",
    "    #\n",
    "    rows['id'] = id_final\n",
    "\n",
    "    # Centroides\n",
    "    points_new.drop(['pt_{}'.format(i) for i in range(1, 16)], axis=1, inplace=True)\n",
    "    points_new.drop('line', axis=1, inplace=True)\n",
    "    points_new.rename(columns={'buffer': 'row'}, inplace=True)\n",
    "    points_new.row = points_new.row + 1  # index 1-based\n",
    "\n",
    "    if row_inverse:\n",
    "        id_row = list(set(list(points_new.row.values)))\n",
    "        id_row_inv = id_row[::-1]\n",
    "        points_new.insert(4, 'row_ord', -99)\n",
    "        for old, new in zip(id_row, id_row_inv):\n",
    "            points_new.at[points_new['row'] == old, 'row_ord'] = new\n",
    "\n",
    "        points_new.drop('row', axis=1, inplace=True)\n",
    "        points_new.rename(columns={'row_ord': 'row'}, inplace=True)\n",
    "\n",
    "    label_id = ['{row:03}-{pt:04}'.format(row=r, pt=p) for r, p in\n",
    "                zip(list(points_new['row']), list(points_new['id_row']))]\n",
    "    points_new.insert(1, 'label_id', label_id)\n",
    "\n",
    "    return rows, points_new\n",
    "\n",
    "\n",
    "# def detect_lines(df_points, df_talhoes):\n",
    "#     all_gaps = []\n",
    "#     all_rows = []\n",
    "#\n",
    "#     for i in df_talhoes.index:\n",
    "#         points_selected = df_points.within(df_talhoes.loc[i, 'geometry'])\n",
    "#         df_points_selected = df_points.loc[points_selected]\n",
    "#\n",
    "#         gaps, rows, points = detect_lines_uni(df_points_selected)\n",
    "#\n",
    "#         all_rows.append(rows)\n",
    "#         all_gaps.append(gaps)\n",
    "#\n",
    "#     return all_gaps, all_rows, points\n",
    "#\n",
    "#\n",
    "# def detect_lines_path(path):\n",
    "#     pontos = gpd.read_file(path + 'centroids.geojson')\n",
    "#     talhoes = gpd.read_file(path + 'talhoes.geojson')\n",
    "#     talhoes.set_index(talhoes.index + 1, inplace=True)\n",
    "#\n",
    "#     falhas_completas, linhas_completas, points = detect_lines(pontos, talhoes)\n",
    "#\n",
    "#     points.to_file(path + 'centroids.geojson', driver='GeoJSON')\n",
    "#     for i, (falhas, linhas) in enumerate(zip(falhas_completas, linhas_completas)):\n",
    "#         falhas.to_file(path + 'gaps.gpkg', layer='{}'.format(i), driver='GPKG')\n",
    "#         linhas.to_file(path + 'lines.gpkg', layer='{}'.format(i), driver='GPKG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "def get_angle(p1, p2):\n",
    "    y = p2.y - p1.y\n",
    "    x = p2.x - p1.x\n",
    "\n",
    "    angle = np.degrees(np.arctan2(y, x))\n",
    "\n",
    "    return angle\n",
    "\n",
    "\n",
    "def get_angle_vertex(p1, p_middle, p2):\n",
    "    get_angle(p_middle, p1)\n",
    "    get_angle(p_middle, p2)\n",
    "\n",
    "    angle = get_angle(p_middle, p1) - get_angle(p_middle, p2)\n",
    "\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bridge 1\n",
    "br1 = [Point(294405.4727, 7515336.3570),\n",
    "       Point(294407.5820, 7515338.6506),\n",
    "       Point(294407.9468, 7515341.5668)]\n",
    "\n",
    "\n",
    "# bridge 2\n",
    "br2 = [Point(294405.4727, 7515336.3570),\n",
    "       Point(294407.5820, 7515338.6506),\n",
    "       Point(294409.7507, 7515340.6267)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle1 = get_angle_vertex(br1[0], br1[1], br1[2])\n",
    "angle2 = get_angle_vertex(br2[0], br2[1], br2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(angle1 - 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(angle2 - 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcnn",
   "language": "python",
   "name": "rcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
