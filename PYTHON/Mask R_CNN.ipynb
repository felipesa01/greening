{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e186c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0, '../PYTHON')\n",
    "import canopy_detection_4b as orca\n",
    "import hlb_utils\n",
    "\n",
    "# from mrcnn.config import Config\n",
    "# import mrcnn.utils as utils\n",
    "# from mrcnn import visualize\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "# from imgaug import augmenters as iaa\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c684dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = '../Mask_RCNN/logs'\n",
    "config = orca.OrangeCanopyConfig()\n",
    "dataset = '../datasets/RGB-DTM/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8c404",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7141ef8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540301ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = '../Mask_RCNN/logs/oranges_trees_canopy20210803T1653/mask_rcnn_oranges_trees_canopy_0061.h5'\n",
    "\n",
    "model.load_weights(weights, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b54b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = '../Mask_RCNN/mask_rcnn_coco.h5'\n",
    "\n",
    "model.load_weights(weights, by_name=True, exclude=[\"mrcnn_class_logits\", \n",
    "                                                   \"mrcnn_bbox_fc\",  \n",
    "                                                   \"mrcnn_bbox\", \n",
    "                                                   \"mrcnn_mask\",\n",
    "                                                   \"conv1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72fa1e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Heads...\n",
      "\n",
      "Starting at epoch 12. LR=0.0002\n",
      "\n",
      "Checkpoint Path: ../Mask_RCNN/logs\\oranges_trees_canopy20211014T2316\\mask_rcnn_oranges_trees_canopy_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training All One..\n",
      "\n",
      "Starting at epoch 12. LR=0.0002\n",
      "\n",
      "Checkpoint Path: ../Mask_RCNN/logs\\oranges_trees_canopy20211014T2316\\mask_rcnn_oranges_trees_canopy_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_2/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_2/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_2/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training_2/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training_2/SGD/gradients/gradients/ROI/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - ETA: 0s - batch: 74.5000 - size: 1.0000 - loss: 5.1317 - rpn_class_loss: 0.0531 - rpn_bbox_loss: 1.1040 - mrcnn_class_loss: 0.0587 - mrcnn_bbox_loss: 0.2196 - mrcnn_mask_loss: 0.2751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 99s 585ms/step - batch: 74.5000 - size: 1.0000 - loss: 5.1317 - rpn_class_loss: 0.0531 - rpn_bbox_loss: 1.1040 - mrcnn_class_loss: 0.0587 - mrcnn_bbox_loss: 0.2196 - mrcnn_mask_loss: 0.2751 - val_loss: 5.5251 - val_rpn_class_loss: 0.0526 - val_rpn_bbox_loss: 1.1230 - val_mrcnn_class_loss: 0.0557 - val_mrcnn_bbox_loss: 0.2936 - val_mrcnn_mask_loss: 0.3168\n",
      "Epoch 14/24\n",
      "150/150 [==============================] - 86s 572ms/step - batch: 74.5000 - size: 1.0000 - loss: 4.3771 - rpn_class_loss: 0.0374 - rpn_bbox_loss: 1.0030 - mrcnn_class_loss: 0.0529 - mrcnn_bbox_loss: 0.1617 - mrcnn_mask_loss: 0.2040 - val_loss: 4.8941 - val_rpn_class_loss: 0.0416 - val_rpn_bbox_loss: 1.0378 - val_mrcnn_class_loss: 0.0909 - val_mrcnn_bbox_loss: 0.2055 - val_mrcnn_mask_loss: 0.2556\n",
      "Epoch 15/24\n",
      "150/150 [==============================] - 87s 580ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.9127 - rpn_class_loss: 0.0376 - rpn_bbox_loss: 0.8332 - mrcnn_class_loss: 0.0661 - mrcnn_bbox_loss: 0.1558 - mrcnn_mask_loss: 0.2115 - val_loss: 4.0608 - val_rpn_class_loss: 0.0348 - val_rpn_bbox_loss: 0.8576 - val_mrcnn_class_loss: 0.0830 - val_mrcnn_bbox_loss: 0.1730 - val_mrcnn_mask_loss: 0.2053\n",
      "Epoch 16/24\n",
      "150/150 [==============================] - 86s 572ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.6205 - rpn_class_loss: 0.0314 - rpn_bbox_loss: 0.7442 - mrcnn_class_loss: 0.0623 - mrcnn_bbox_loss: 0.1591 - mrcnn_mask_loss: 0.2097 - val_loss: 3.6616 - val_rpn_class_loss: 0.0419 - val_rpn_bbox_loss: 0.8184 - val_mrcnn_class_loss: 0.0693 - val_mrcnn_bbox_loss: 0.1160 - val_mrcnn_mask_loss: 0.1749\n",
      "Epoch 17/24\n",
      "150/150 [==============================] - 90s 598ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.1676 - rpn_class_loss: 0.0334 - rpn_bbox_loss: 0.6305 - mrcnn_class_loss: 0.0787 - mrcnn_bbox_loss: 0.1271 - mrcnn_mask_loss: 0.1862 - val_loss: 3.3692 - val_rpn_class_loss: 0.0378 - val_rpn_bbox_loss: 0.6603 - val_mrcnn_class_loss: 0.0739 - val_mrcnn_bbox_loss: 0.1483 - val_mrcnn_mask_loss: 0.2027\n",
      "Epoch 18/24\n",
      "150/150 [==============================] - 87s 578ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.0727 - rpn_class_loss: 0.0327 - rpn_bbox_loss: 0.5743 - mrcnn_class_loss: 0.0797 - mrcnn_bbox_loss: 0.1390 - mrcnn_mask_loss: 0.1985 - val_loss: 3.3520 - val_rpn_class_loss: 0.0303 - val_rpn_bbox_loss: 0.7043 - val_mrcnn_class_loss: 0.0738 - val_mrcnn_bbox_loss: 0.1369 - val_mrcnn_mask_loss: 0.1722\n",
      "Epoch 19/24\n",
      "150/150 [==============================] - 87s 580ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.8585 - rpn_class_loss: 0.0276 - rpn_bbox_loss: 0.5355 - mrcnn_class_loss: 0.0711 - mrcnn_bbox_loss: 0.1351 - mrcnn_mask_loss: 0.1836 - val_loss: 2.7016 - val_rpn_class_loss: 0.0253 - val_rpn_bbox_loss: 0.5516 - val_mrcnn_class_loss: 0.0792 - val_mrcnn_bbox_loss: 0.0944 - val_mrcnn_mask_loss: 0.1500\n",
      "Epoch 20/24\n",
      "150/150 [==============================] - 90s 598ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.3814 - rpn_class_loss: 0.0255 - rpn_bbox_loss: 0.4351 - mrcnn_class_loss: 0.0730 - mrcnn_bbox_loss: 0.0982 - mrcnn_mask_loss: 0.1620 - val_loss: 3.1620 - val_rpn_class_loss: 0.0269 - val_rpn_bbox_loss: 0.6238 - val_mrcnn_class_loss: 0.0914 - val_mrcnn_bbox_loss: 0.1288 - val_mrcnn_mask_loss: 0.1831\n",
      "Epoch 21/24\n",
      "150/150 [==============================] - 87s 577ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.5471 - rpn_class_loss: 0.0242 - rpn_bbox_loss: 0.4440 - mrcnn_class_loss: 0.0784 - mrcnn_bbox_loss: 0.1226 - mrcnn_mask_loss: 0.1798 - val_loss: 3.0383 - val_rpn_class_loss: 0.0272 - val_rpn_bbox_loss: 0.6045 - val_mrcnn_class_loss: 0.0815 - val_mrcnn_bbox_loss: 0.1133 - val_mrcnn_mask_loss: 0.1863\n",
      "Epoch 22/24\n",
      "150/150 [==============================] - 87s 582ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.4121 - rpn_class_loss: 0.0250 - rpn_bbox_loss: 0.4150 - mrcnn_class_loss: 0.0722 - mrcnn_bbox_loss: 0.1087 - mrcnn_mask_loss: 0.1830 - val_loss: 2.6719 - val_rpn_class_loss: 0.0225 - val_rpn_bbox_loss: 0.5282 - val_mrcnn_class_loss: 0.0711 - val_mrcnn_bbox_loss: 0.1193 - val_mrcnn_mask_loss: 0.1495\n",
      "Epoch 23/24\n",
      "150/150 [==============================] - 90s 599ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.1790 - rpn_class_loss: 0.0245 - rpn_bbox_loss: 0.3605 - mrcnn_class_loss: 0.0800 - mrcnn_bbox_loss: 0.0961 - mrcnn_mask_loss: 0.1652 - val_loss: 2.5327 - val_rpn_class_loss: 0.0279 - val_rpn_bbox_loss: 0.5005 - val_mrcnn_class_loss: 0.0688 - val_mrcnn_bbox_loss: 0.1035 - val_mrcnn_mask_loss: 0.1436\n",
      "Epoch 24/24\n",
      "150/150 [==============================] - 91s 609ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.3229 - rpn_class_loss: 0.0256 - rpn_bbox_loss: 0.4031 - mrcnn_class_loss: 0.0757 - mrcnn_bbox_loss: 0.1047 - mrcnn_mask_loss: 0.1653 - val_loss: 2.3471 - val_rpn_class_loss: 0.0216 - val_rpn_bbox_loss: 0.4471 - val_mrcnn_class_loss: 0.0741 - val_mrcnn_bbox_loss: 0.0972 - val_mrcnn_mask_loss: 0.1423\n",
      "Training All Two...\n",
      "\n",
      "Starting at epoch 24. LR=2e-05\n",
      "\n",
      "Checkpoint Path: ../Mask_RCNN/logs\\oranges_trees_canopy20211014T2316\\mask_rcnn_oranges_trees_canopy_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_4/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_4/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_4/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training_4/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training_4/SGD/gradients/gradients/ROI/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - ETA: 0s - batch: 74.5000 - size: 1.0000 - loss: 2.5015 - rpn_class_loss: 0.0215 - rpn_bbox_loss: 0.3072 - mrcnn_class_loss: 0.0650 - mrcnn_bbox_loss: 0.0836 - mrcnn_mask_loss: 0.1480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 98s 584ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.5015 - rpn_class_loss: 0.0215 - rpn_bbox_loss: 0.3072 - mrcnn_class_loss: 0.0650 - mrcnn_bbox_loss: 0.0836 - mrcnn_mask_loss: 0.1480 - val_loss: 3.0079 - val_rpn_class_loss: 0.0172 - val_rpn_bbox_loss: 0.4453 - val_mrcnn_class_loss: 0.0659 - val_mrcnn_bbox_loss: 0.0847 - val_mrcnn_mask_loss: 0.1389\n",
      "Epoch 26/36\n",
      "150/150 [==============================] - 88s 584ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.4791 - rpn_class_loss: 0.0200 - rpn_bbox_loss: 0.2991 - mrcnn_class_loss: 0.0690 - mrcnn_bbox_loss: 0.0793 - mrcnn_mask_loss: 0.1523 - val_loss: 3.2406 - val_rpn_class_loss: 0.0261 - val_rpn_bbox_loss: 0.4725 - val_mrcnn_class_loss: 0.0772 - val_mrcnn_bbox_loss: 0.0890 - val_mrcnn_mask_loss: 0.1453\n",
      "Epoch 27/36\n",
      "150/150 [==============================] - 83s 556ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.2706 - rpn_class_loss: 0.0177 - rpn_bbox_loss: 0.2657 - mrcnn_class_loss: 0.0608 - mrcnn_bbox_loss: 0.0771 - mrcnn_mask_loss: 0.1464 - val_loss: 3.0902 - val_rpn_class_loss: 0.0187 - val_rpn_bbox_loss: 0.4524 - val_mrcnn_class_loss: 0.0728 - val_mrcnn_bbox_loss: 0.0873 - val_mrcnn_mask_loss: 0.1413\n",
      "Epoch 28/36\n",
      "150/150 [==============================] - 89s 593ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.3534 - rpn_class_loss: 0.0234 - rpn_bbox_loss: 0.2838 - mrcnn_class_loss: 0.0670 - mrcnn_bbox_loss: 0.0725 - mrcnn_mask_loss: 0.1416 - val_loss: 3.0916 - val_rpn_class_loss: 0.0242 - val_rpn_bbox_loss: 0.4621 - val_mrcnn_class_loss: 0.0635 - val_mrcnn_bbox_loss: 0.0844 - val_mrcnn_mask_loss: 0.1386\n",
      "Epoch 29/36\n",
      "150/150 [==============================] - 86s 577ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.2811 - rpn_class_loss: 0.0164 - rpn_bbox_loss: 0.2729 - mrcnn_class_loss: 0.0626 - mrcnn_bbox_loss: 0.0730 - mrcnn_mask_loss: 0.1454 - val_loss: 3.2754 - val_rpn_class_loss: 0.0230 - val_rpn_bbox_loss: 0.4858 - val_mrcnn_class_loss: 0.0685 - val_mrcnn_bbox_loss: 0.0921 - val_mrcnn_mask_loss: 0.1494\n",
      "Epoch 30/36\n",
      "150/150 [==============================] - 89s 591ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.2972 - rpn_class_loss: 0.0235 - rpn_bbox_loss: 0.2609 - mrcnn_class_loss: 0.0664 - mrcnn_bbox_loss: 0.0762 - mrcnn_mask_loss: 0.1474 - val_loss: 2.8079 - val_rpn_class_loss: 0.0200 - val_rpn_bbox_loss: 0.4122 - val_mrcnn_class_loss: 0.0581 - val_mrcnn_bbox_loss: 0.0768 - val_mrcnn_mask_loss: 0.1350\n",
      "Epoch 31/36\n",
      "150/150 [==============================] - 86s 577ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.3478 - rpn_class_loss: 0.0194 - rpn_bbox_loss: 0.2760 - mrcnn_class_loss: 0.0693 - mrcnn_bbox_loss: 0.0753 - mrcnn_mask_loss: 0.1470 - val_loss: 2.8652 - val_rpn_class_loss: 0.0154 - val_rpn_bbox_loss: 0.4252 - val_mrcnn_class_loss: 0.0604 - val_mrcnn_bbox_loss: 0.0845 - val_mrcnn_mask_loss: 0.1308\n",
      "Epoch 32/36\n",
      "150/150 [==============================] - 86s 574ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.3933 - rpn_class_loss: 0.0206 - rpn_bbox_loss: 0.2728 - mrcnn_class_loss: 0.0669 - mrcnn_bbox_loss: 0.0865 - mrcnn_mask_loss: 0.1516 - val_loss: 2.8670 - val_rpn_class_loss: 0.0203 - val_rpn_bbox_loss: 0.4091 - val_mrcnn_class_loss: 0.0660 - val_mrcnn_bbox_loss: 0.0824 - val_mrcnn_mask_loss: 0.1389\n",
      "Epoch 33/36\n",
      "150/150 [==============================] - 87s 583ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.2607 - rpn_class_loss: 0.0196 - rpn_bbox_loss: 0.2658 - mrcnn_class_loss: 0.0643 - mrcnn_bbox_loss: 0.0694 - mrcnn_mask_loss: 0.1460 - val_loss: 3.0685 - val_rpn_class_loss: 0.0239 - val_rpn_bbox_loss: 0.4429 - val_mrcnn_class_loss: 0.0715 - val_mrcnn_bbox_loss: 0.0881 - val_mrcnn_mask_loss: 0.1406\n",
      "Epoch 34/36\n",
      "150/150 [==============================] - 88s 587ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.2447 - rpn_class_loss: 0.0186 - rpn_bbox_loss: 0.2557 - mrcnn_class_loss: 0.0676 - mrcnn_bbox_loss: 0.0732 - mrcnn_mask_loss: 0.1460 - val_loss: 2.8741 - val_rpn_class_loss: 0.0173 - val_rpn_bbox_loss: 0.4073 - val_mrcnn_class_loss: 0.0617 - val_mrcnn_bbox_loss: 0.0915 - val_mrcnn_mask_loss: 0.1407\n",
      "Epoch 35/36\n",
      "150/150 [==============================] - 87s 580ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.2140 - rpn_class_loss: 0.0179 - rpn_bbox_loss: 0.2499 - mrcnn_class_loss: 0.0664 - mrcnn_bbox_loss: 0.0721 - mrcnn_mask_loss: 0.1472 - val_loss: 3.0408 - val_rpn_class_loss: 0.0214 - val_rpn_bbox_loss: 0.4367 - val_mrcnn_class_loss: 0.0671 - val_mrcnn_bbox_loss: 0.0945 - val_mrcnn_mask_loss: 0.1406\n",
      "Epoch 36/36\n",
      "150/150 [==============================] - 90s 601ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.1472 - rpn_class_loss: 0.0169 - rpn_bbox_loss: 0.2472 - mrcnn_class_loss: 0.0693 - mrcnn_bbox_loss: 0.0636 - mrcnn_mask_loss: 0.1397 - val_loss: 2.9676 - val_rpn_class_loss: 0.0244 - val_rpn_bbox_loss: 0.4412 - val_mrcnn_class_loss: 0.0611 - val_mrcnn_bbox_loss: 0.0824 - val_mrcnn_mask_loss: 0.1327\n",
      "Training All Tree...\n",
      "\n",
      "Starting at epoch 36. LR=2e-06\n",
      "\n",
      "Checkpoint Path: ../Mask_RCNN/logs\\oranges_trees_canopy20211014T2316\\mask_rcnn_oranges_trees_canopy_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_6/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_6/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_6/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training_6/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training_6/SGD/gradients/gradients/ROI/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - ETA: 0s - batch: 74.5000 - size: 1.0000 - loss: 2.9788 - rpn_class_loss: 0.0185 - rpn_bbox_loss: 0.2687 - mrcnn_class_loss: 0.0719 - mrcnn_bbox_loss: 0.0808 - mrcnn_mask_loss: 0.1559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 105s 620ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.9788 - rpn_class_loss: 0.0185 - rpn_bbox_loss: 0.2687 - mrcnn_class_loss: 0.0719 - mrcnn_bbox_loss: 0.0808 - mrcnn_mask_loss: 0.1559 - val_loss: 3.5075 - val_rpn_class_loss: 0.0197 - val_rpn_bbox_loss: 0.3997 - val_mrcnn_class_loss: 0.0618 - val_mrcnn_bbox_loss: 0.0868 - val_mrcnn_mask_loss: 0.1335\n",
      "Epoch 38/48\n",
      "150/150 [==============================] - 91s 605ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.7657 - rpn_class_loss: 0.0209 - rpn_bbox_loss: 0.2602 - mrcnn_class_loss: 0.0684 - mrcnn_bbox_loss: 0.0645 - mrcnn_mask_loss: 0.1391 - val_loss: 3.4183 - val_rpn_class_loss: 0.0169 - val_rpn_bbox_loss: 0.3919 - val_mrcnn_class_loss: 0.0656 - val_mrcnn_bbox_loss: 0.0789 - val_mrcnn_mask_loss: 0.1303\n",
      "Epoch 39/48\n",
      "150/150 [==============================] - 90s 603ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.6553 - rpn_class_loss: 0.0179 - rpn_bbox_loss: 0.2426 - mrcnn_class_loss: 0.0638 - mrcnn_bbox_loss: 0.0668 - mrcnn_mask_loss: 0.1399 - val_loss: 3.3907 - val_rpn_class_loss: 0.0218 - val_rpn_bbox_loss: 0.3726 - val_mrcnn_class_loss: 0.0719 - val_mrcnn_bbox_loss: 0.0769 - val_mrcnn_mask_loss: 0.1348\n",
      "Epoch 40/48\n",
      "150/150 [==============================] - 90s 602ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.6270 - rpn_class_loss: 0.0155 - rpn_bbox_loss: 0.2271 - mrcnn_class_loss: 0.0659 - mrcnn_bbox_loss: 0.0720 - mrcnn_mask_loss: 0.1449 - val_loss: 3.5649 - val_rpn_class_loss: 0.0185 - val_rpn_bbox_loss: 0.4084 - val_mrcnn_class_loss: 0.0655 - val_mrcnn_bbox_loss: 0.0849 - val_mrcnn_mask_loss: 0.1357\n",
      "Epoch 41/48\n",
      "150/150 [==============================] - 88s 587ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.7243 - rpn_class_loss: 0.0194 - rpn_bbox_loss: 0.2408 - mrcnn_class_loss: 0.0662 - mrcnn_bbox_loss: 0.0735 - mrcnn_mask_loss: 0.1450 - val_loss: 3.3946 - val_rpn_class_loss: 0.0197 - val_rpn_bbox_loss: 0.3831 - val_mrcnn_class_loss: 0.0610 - val_mrcnn_bbox_loss: 0.0802 - val_mrcnn_mask_loss: 0.1349\n",
      "Epoch 42/48\n",
      "150/150 [==============================] - 89s 596ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.6498 - rpn_class_loss: 0.0175 - rpn_bbox_loss: 0.2306 - mrcnn_class_loss: 0.0630 - mrcnn_bbox_loss: 0.0720 - mrcnn_mask_loss: 0.1468 - val_loss: 3.3322 - val_rpn_class_loss: 0.0197 - val_rpn_bbox_loss: 0.3728 - val_mrcnn_class_loss: 0.0675 - val_mrcnn_bbox_loss: 0.0736 - val_mrcnn_mask_loss: 0.1328\n",
      "Epoch 43/48\n",
      "150/150 [==============================] - 90s 603ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.8557 - rpn_class_loss: 0.0208 - rpn_bbox_loss: 0.2671 - mrcnn_class_loss: 0.0674 - mrcnn_bbox_loss: 0.0703 - mrcnn_mask_loss: 0.1455 - val_loss: 3.8814 - val_rpn_class_loss: 0.0208 - val_rpn_bbox_loss: 0.4683 - val_mrcnn_class_loss: 0.0577 - val_mrcnn_bbox_loss: 0.0943 - val_mrcnn_mask_loss: 0.1352\n",
      "Epoch 44/48\n",
      "150/150 [==============================] - 89s 596ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.8018 - rpn_class_loss: 0.0187 - rpn_bbox_loss: 0.2638 - mrcnn_class_loss: 0.0682 - mrcnn_bbox_loss: 0.0648 - mrcnn_mask_loss: 0.1449 - val_loss: 3.5320 - val_rpn_class_loss: 0.0156 - val_rpn_bbox_loss: 0.4037 - val_mrcnn_class_loss: 0.0666 - val_mrcnn_bbox_loss: 0.0854 - val_mrcnn_mask_loss: 0.1351\n",
      "Epoch 45/48\n",
      "150/150 [==============================] - 90s 602ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.7414 - rpn_class_loss: 0.0241 - rpn_bbox_loss: 0.2499 - mrcnn_class_loss: 0.0576 - mrcnn_bbox_loss: 0.0702 - mrcnn_mask_loss: 0.1464 - val_loss: 3.7051 - val_rpn_class_loss: 0.0200 - val_rpn_bbox_loss: 0.4359 - val_mrcnn_class_loss: 0.0610 - val_mrcnn_bbox_loss: 0.0910 - val_mrcnn_mask_loss: 0.1331\n",
      "Epoch 46/48\n",
      "150/150 [==============================] - 88s 587ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.6544 - rpn_class_loss: 0.0225 - rpn_bbox_loss: 0.2377 - mrcnn_class_loss: 0.0689 - mrcnn_bbox_loss: 0.0603 - mrcnn_mask_loss: 0.1415 - val_loss: 3.7610 - val_rpn_class_loss: 0.0188 - val_rpn_bbox_loss: 0.4416 - val_mrcnn_class_loss: 0.0651 - val_mrcnn_bbox_loss: 0.0901 - val_mrcnn_mask_loss: 0.1366\n",
      "Epoch 47/48\n",
      "150/150 [==============================] - 88s 589ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.7699 - rpn_class_loss: 0.0202 - rpn_bbox_loss: 0.2425 - mrcnn_class_loss: 0.0698 - mrcnn_bbox_loss: 0.0703 - mrcnn_mask_loss: 0.1512 - val_loss: 3.5747 - val_rpn_class_loss: 0.0204 - val_rpn_bbox_loss: 0.4072 - val_mrcnn_class_loss: 0.0677 - val_mrcnn_bbox_loss: 0.0824 - val_mrcnn_mask_loss: 0.1371\n",
      "Epoch 48/48\n",
      "150/150 [==============================] - 91s 605ms/step - batch: 74.5000 - size: 1.0000 - loss: 2.7770 - rpn_class_loss: 0.0231 - rpn_bbox_loss: 0.2440 - mrcnn_class_loss: 0.0720 - mrcnn_bbox_loss: 0.0718 - mrcnn_mask_loss: 0.1444 - val_loss: 3.5479 - val_rpn_class_loss: 0.0202 - val_rpn_bbox_loss: 0.3947 - val_mrcnn_class_loss: 0.0699 - val_mrcnn_bbox_loss: 0.0834 - val_mrcnn_mask_loss: 0.1414\n",
      "Training All Four...\n",
      "\n",
      "Starting at epoch 48. LR=2.0000000000000002e-07\n",
      "\n",
      "Checkpoint Path: ../Mask_RCNN/logs\\oranges_trees_canopy20211014T2316\\mask_rcnn_oranges_trees_canopy_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training_8/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training_8/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training_8/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training_8/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training_8/SGD/gradients/gradients/ROI/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - ETA: 0s - batch: 74.5000 - size: 1.0000 - loss: 3.3345 - rpn_class_loss: 0.0182 - rpn_bbox_loss: 0.2547 - mrcnn_class_loss: 0.0695 - mrcnn_bbox_loss: 0.0683 - mrcnn_mask_loss: 0.1450"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\anaconda3\\envs\\rcnn\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 102s 596ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.3345 - rpn_class_loss: 0.0182 - rpn_bbox_loss: 0.2547 - mrcnn_class_loss: 0.0695 - mrcnn_bbox_loss: 0.0683 - mrcnn_mask_loss: 0.1450 - val_loss: 4.4494 - val_rpn_class_loss: 0.0184 - val_rpn_bbox_loss: 0.4205 - val_mrcnn_class_loss: 0.0708 - val_mrcnn_bbox_loss: 0.0913 - val_mrcnn_mask_loss: 0.1406\n",
      "Epoch 50/60\n",
      "150/150 [==============================] - 88s 587ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.1610 - rpn_class_loss: 0.0170 - rpn_bbox_loss: 0.2352 - mrcnn_class_loss: 0.0647 - mrcnn_bbox_loss: 0.0673 - mrcnn_mask_loss: 0.1425 - val_loss: 4.3207 - val_rpn_class_loss: 0.0186 - val_rpn_bbox_loss: 0.4162 - val_mrcnn_class_loss: 0.0611 - val_mrcnn_bbox_loss: 0.0877 - val_mrcnn_mask_loss: 0.1366\n",
      "Epoch 51/60\n",
      "150/150 [==============================] - 87s 583ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.2379 - rpn_class_loss: 0.0210 - rpn_bbox_loss: 0.2351 - mrcnn_class_loss: 0.0658 - mrcnn_bbox_loss: 0.0723 - mrcnn_mask_loss: 0.1455 - val_loss: 4.3346 - val_rpn_class_loss: 0.0150 - val_rpn_bbox_loss: 0.4121 - val_mrcnn_class_loss: 0.0657 - val_mrcnn_bbox_loss: 0.0876 - val_mrcnn_mask_loss: 0.1419\n",
      "Epoch 52/60\n",
      "150/150 [==============================] - 89s 593ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.2126 - rpn_class_loss: 0.0195 - rpn_bbox_loss: 0.2337 - mrcnn_class_loss: 0.0693 - mrcnn_bbox_loss: 0.0670 - mrcnn_mask_loss: 0.1459 - val_loss: 4.3606 - val_rpn_class_loss: 0.0200 - val_rpn_bbox_loss: 0.4201 - val_mrcnn_class_loss: 0.0624 - val_mrcnn_bbox_loss: 0.0843 - val_mrcnn_mask_loss: 0.1399\n",
      "Epoch 53/60\n",
      "150/150 [==============================] - 85s 569ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.2596 - rpn_class_loss: 0.0179 - rpn_bbox_loss: 0.2455 - mrcnn_class_loss: 0.0618 - mrcnn_bbox_loss: 0.0695 - mrcnn_mask_loss: 0.1485 - val_loss: 4.3910 - val_rpn_class_loss: 0.0217 - val_rpn_bbox_loss: 0.4258 - val_mrcnn_class_loss: 0.0600 - val_mrcnn_bbox_loss: 0.0857 - val_mrcnn_mask_loss: 0.1387\n",
      "Epoch 54/60\n",
      "150/150 [==============================] - 89s 592ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.4507 - rpn_class_loss: 0.0195 - rpn_bbox_loss: 0.2629 - mrcnn_class_loss: 0.0748 - mrcnn_bbox_loss: 0.0712 - mrcnn_mask_loss: 0.1466 - val_loss: 4.3550 - val_rpn_class_loss: 0.0165 - val_rpn_bbox_loss: 0.4215 - val_mrcnn_class_loss: 0.0609 - val_mrcnn_bbox_loss: 0.0884 - val_mrcnn_mask_loss: 0.1386\n",
      "Epoch 55/60\n",
      "150/150 [==============================] - 87s 581ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.2861 - rpn_class_loss: 0.0195 - rpn_bbox_loss: 0.2402 - mrcnn_class_loss: 0.0701 - mrcnn_bbox_loss: 0.0705 - mrcnn_mask_loss: 0.1473 - val_loss: 4.2434 - val_rpn_class_loss: 0.0165 - val_rpn_bbox_loss: 0.4133 - val_mrcnn_class_loss: 0.0570 - val_mrcnn_bbox_loss: 0.0844 - val_mrcnn_mask_loss: 0.1361\n",
      "Epoch 56/60\n",
      "150/150 [==============================] - 87s 584ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.1549 - rpn_class_loss: 0.0208 - rpn_bbox_loss: 0.2349 - mrcnn_class_loss: 0.0635 - mrcnn_bbox_loss: 0.0649 - mrcnn_mask_loss: 0.1417 - val_loss: 4.5705 - val_rpn_class_loss: 0.0166 - val_rpn_bbox_loss: 0.4475 - val_mrcnn_class_loss: 0.0628 - val_mrcnn_bbox_loss: 0.0936 - val_mrcnn_mask_loss: 0.1413\n",
      "Epoch 57/60\n",
      "150/150 [==============================] - 87s 579ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.0875 - rpn_class_loss: 0.0182 - rpn_bbox_loss: 0.2297 - mrcnn_class_loss: 0.0621 - mrcnn_bbox_loss: 0.0629 - mrcnn_mask_loss: 0.1416 - val_loss: 4.1127 - val_rpn_class_loss: 0.0176 - val_rpn_bbox_loss: 0.3849 - val_mrcnn_class_loss: 0.0642 - val_mrcnn_bbox_loss: 0.0809 - val_mrcnn_mask_loss: 0.1378\n",
      "Epoch 58/60\n",
      "150/150 [==============================] - 88s 592ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.2360 - rpn_class_loss: 0.0225 - rpn_bbox_loss: 0.2431 - mrcnn_class_loss: 0.0608 - mrcnn_bbox_loss: 0.0669 - mrcnn_mask_loss: 0.1460 - val_loss: 4.4215 - val_rpn_class_loss: 0.0201 - val_rpn_bbox_loss: 0.4295 - val_mrcnn_class_loss: 0.0595 - val_mrcnn_bbox_loss: 0.0846 - val_mrcnn_mask_loss: 0.1432\n",
      "Epoch 59/60\n",
      "150/150 [==============================] - 89s 596ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.4559 - rpn_class_loss: 0.0208 - rpn_bbox_loss: 0.2575 - mrcnn_class_loss: 0.0742 - mrcnn_bbox_loss: 0.0755 - mrcnn_mask_loss: 0.1480 - val_loss: 3.8798 - val_rpn_class_loss: 0.0170 - val_rpn_bbox_loss: 0.3597 - val_mrcnn_class_loss: 0.0654 - val_mrcnn_bbox_loss: 0.0723 - val_mrcnn_mask_loss: 0.1322\n",
      "Epoch 60/60\n",
      "150/150 [==============================] - 89s 596ms/step - batch: 74.5000 - size: 1.0000 - loss: 3.3771 - rpn_class_loss: 0.0195 - rpn_bbox_loss: 0.2474 - mrcnn_class_loss: 0.0735 - mrcnn_bbox_loss: 0.0736 - mrcnn_mask_loss: 0.1489 - val_loss: 4.0726 - val_rpn_class_loss: 0.0155 - val_rpn_bbox_loss: 0.3935 - val_mrcnn_class_loss: 0.0597 - val_mrcnn_bbox_loss: 0.0767 - val_mrcnn_mask_loss: 0.1334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training Finished!!!!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca.train(model, config, 'all_4', dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d465c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b080ab13",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f1b096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/felipesa/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:From /home/felipesa/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode='inference', config=config, model_dir=logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece0234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 61\n"
     ]
    }
   ],
   "source": [
    "weights = '../Mask_RCNN/logs/oranges_trees_canopy20210803T1653/mask_rcnn_oranges_trees_canopy_0061.h5'\n",
    "\n",
    "model.load_weights(weights, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2f6d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 42, 43, 44, 45, 46, 47, 48, 49, 50]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "img_test = gpd.read_file('../datasets/odm_orthophoto/img_grid_edit.geojson')\n",
    "ids = list(img_test.loc[img_test['split_samples'] == 'test'].index)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c4846c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipesa/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Done\n",
      "Compilando resultado\n",
      "Concluído!\n"
     ]
    }
   ],
   "source": [
    "results = orca.prediction(model, dataset, id_list=ids, verbose=0, first=False, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21e618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcnn",
   "language": "python",
   "name": "rcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
