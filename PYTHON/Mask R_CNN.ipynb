{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a205e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../PYTHON/HLB')\n",
    "import orange_canopy as orca\n",
    "\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage\n",
    "\n",
    "logs = '../Mask_RCNN/logs'\n",
    "dataset = '../Mask_RCNN/datasets/canopy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa402c",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60855da",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = orca.OrangeCanopyConfig()\n",
    "# config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84191dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = '../Mask_RCNN/mask_rcnn_coco.h5'\n",
    "# weights = '../Mask_RCNN/logs/trees.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55585dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030c01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights, \n",
    "                   by_name=True,\n",
    "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c120b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = orca.OrangeCanopyDataset()\n",
    "train_dataset.load_data(dataset, 'train')\n",
    "train_dataset.prepare()\n",
    "\n",
    "val_dataset = orca.OrangeCanopyDataset()\n",
    "val_dataset.load_data(dataset, 'val')\n",
    "val_dataset.prepare()\n",
    "\n",
    "augmentation = iaa.SomeOf((0, 2), [iaa.Fliplr(0.5), iaa.Flipud(0.5), iaa.OneOf([iaa.Affine(rotate=90), iaa.Affine(rotate=180), iaa.Affine(rotate=270)]), iaa.Multiply((0.5, 1.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15279714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.0002\n",
      "\n",
      "Checkpoint Path: ../Mask_RCNN/logs/oranges_trees_canopy20210803T1653/mask_rcnn_oranges_trees_canopy_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/user/anaconda3/envs/rcnn/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape_1:0\", shape=(6000,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape:0\", shape=(6000, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/500 [================>.............] - ETA: 27:07 - batch: 142.5000 - size: 1.0000 - loss: 5.2168 - rpn_class_loss: 0.3220 - rpn_bbox_loss: 3.8942 - mrcnn_class_loss: 0.1600 - mrcnn_bbox_loss: 0.4433 - mrcnn_mask_loss: 0.3974"
     ]
    }
   ],
   "source": [
    "model.train(train_dataset, val_dataset,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=4,\n",
    "            augmentation=augmentation,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd55f0",
   "metadata": {},
   "source": [
    "# InferÃªncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ea6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(orca.OrangeCanopyConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    # I kept the same configuration of the training\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    NAME = 'trees'\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    BACKBONE = \"resnet50\"\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    BACKBONE_STRIDES = [4, 8, 16, 32, 64]\n",
    "    RPN_ANCHOR_SCALES = (4, 8, 16, 32, 64)\n",
    "    USE_MINI_MASK = False\n",
    "    IMAGE_CHANNEL_COUNT = 3\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "    MEAN_PIXEL = np.array([105, 236, 189])\n",
    "    DETECTION_NMS_THRESHOLD = 0.3\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    MAX_GT_INSTANCES = 100\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    TRAIN_ROIS_PER_IMAGE = 100\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 100\n",
    "    \n",
    "config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b501d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode='inference', config=config, model_dir=logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ad07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = '../Mask_RCNN/logs/trees.h5'\n",
    "\n",
    "model.load_weights(weights, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test_dir = os.path.join(dataset, 'real_test', 'images')\n",
    "images_test_dir = '../IMGS'\n",
    "\n",
    "image_paths = []\n",
    "for filename in os.listdir(images_test_dir):\n",
    "    if os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg']:\n",
    "        image_paths.append(os.path.512join(images_test_dir, filename))\n",
    "\n",
    "for image_path in image_paths:\n",
    "    img = skimage.io.imread(image_path)\n",
    "    img_arr = np.array(img)\n",
    "    results = model.detect([img_arr], verbose=1)\n",
    "\n",
    "    r = results[0]\n",
    "    visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'],\n",
    "                                val_dataset.class_names, r['scores'], figsize=(5, 5))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf34ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'],\n",
    "                                val_dataset.class_names, r['scores'], figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba7847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcnn",
   "language": "python",
   "name": "rcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
